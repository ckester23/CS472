# -*- coding: utf-8 -*-
"""CS472_Final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EB6g5JF4hMHUOxUX34IqtVpnWpug3e0u
"""
import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # decreases log messages
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import keras_tuner as tk
import numpy as np
from concurrent.futures import ThreadPoolExecutor
import sys

import glob
import PIL.Image as Image
import matplotlib.pyplot as plt
from tqdm import tqdm

# Data config
DATA_DIR = './train'
BUFFER = 32  # Half-size of papyrus patches we'll use as model inputs
Z_DIM = 20   # Number of slices in the z direction. Max value is 64 - Z_START
Z_START = 16  # Offset of slices in the z direction
SHARED_HEIGHT = 4000  # Height to resize all papyrii
LOAD_MODEL=False
TUNE=True
MODEL_FILE="model.keras"
RAP_TEST=len(sys.argv) > 1

NUM_TRAIN_POITNS = 700 # Defines how many points we want to train on
BATCH_SIZE = 32

def load_and_process_image(filename):
    img = Image.open(filename)
    img = resize(img)
    return np.array(img, dtype="float32")

def load_volume(split, index):
    # Load the 3d x-ray scan, one slice at a time
    z_slices_fnames = sorted(glob.glob(f"{DATA_DIR}/{split}/{index}/surface_volume/*.tif"))[Z_START:Z_START + Z_DIM]
    with ThreadPoolExecutor() as executor:
        z_slices = list(tqdm(executor.map(load_and_process_image, z_slices_fnames), total=len(z_slices_fnames)))
    return tf.stack(z_slices, axis=-1)

def resize(img):
    current_width, current_height = img.size
    aspect_ratio = current_width / current_height
    new_width = int(SHARED_HEIGHT * aspect_ratio)
    new_size = (new_width, SHARED_HEIGHT)
    img = img.resize(new_size)
    return img

def load_mask(split, index):
    img = Image.open(f"{DATA_DIR}/{split}/{index}/mask.png").convert('1')
    img = resize(img)
    return tf.convert_to_tensor(img, dtype="bool")

def load_labels(split, index):
    img = Image.open(f"{DATA_DIR}/{split}/{index}/inklabels.png")
    img = resize(img)
    return tf.convert_to_tensor(img, dtype="bool")

val_location = (1300, 1000) # Holdout data to validate
val_zone_size = (600, 2000) # Size of that holdout data

mask_train_1 = load_mask(split="train", index=1)
label_train_1 = load_labels(split="train", index=1)
mask_train_2 = load_mask(split="train", index=2)
label_train_2 = load_labels(split="train", index=2)

mask = tf.concat([mask_train_1, mask_train_2], axis=1) # Will add the other two training sets also
labels = tf.concat([label_train_1, label_train_2],axis=1)

del mask_train_1
del mask_train_2
del label_train_1
del label_train_2

def sample_random_location(shape): # Get a random point in the data 
    random_train_x = tf.random.uniform(shape=(), minval=BUFFER, maxval=shape[0] - BUFFER - 1, dtype="int32")
    random_train_y = tf.random.uniform(shape=(), minval=BUFFER, maxval=shape[1] - BUFFER - 1, dtype="int32")
    random_train_location = tf.stack([random_train_x, random_train_y])
    return random_train_location

def is_in_masked_zone(location, mask): # checks if a location along with the mask is in said mask
    return mask[location[0], location[1]]

sample_random_location_train = lambda x: sample_random_location(mask.shape) # samples a random location in the data
is_in_mask_train = lambda x: is_in_masked_zone(x, mask) # Checks if the location is within the masked area

def is_in_val_zone(location, val_location, val_zone_size): # checks if location point is in holdout data section
    x = location[0]
    y = location[1]
    x_match = val_location[0] - BUFFER <= x <= val_location[0] + val_zone_size[0] + BUFFER
    y_match = val_location[1] - BUFFER <= y <= val_location[1] + val_zone_size[1] + BUFFER
    return x_match and y_match

def is_proper_train_location(location): # checks if point is not in holdout and is in training data space
    return not is_in_val_zone(location, val_location, val_zone_size) and is_in_mask_train(location)

#                                                            V This repeat function allows us to gather as main points as we theoretically want
train_locations_ds = tf.data.Dataset.from_tensor_slices([0]).repeat().map(sample_random_location_train, num_parallel_calls=tf.data.AUTOTUNE) # Gathers a bunch of points
train_locations_ds = train_locations_ds.filter(is_proper_train_location) # Checks if they are good points

volume_1 = load_volume(split="train", index=1) # load x-ray volume data
volume_2 = load_volume(split="train", index=2) # load x-ray volume data
volume = tf.concat([volume_1, volume_2], axis=1) # combine volumes

del volume_1
del volume_2

def extract_subvolume(location, volume): # Get the volume of sample location
    x = location[0]
    y = location[1]
    subvolume = volume[x-BUFFER:x+BUFFER, y-BUFFER:y+BUFFER, :] # subvolume shape = (BUFFER*2, BUFFER*2, 20)
    subvolume = tf.cast(subvolume, dtype="float32") / 65535.
    return subvolume

def extract_labels(location, labels): # Get the corresponding training labels
    x = location[0]
    y = location[1]
    label = labels[x-BUFFER:x+BUFFER, y-BUFFER:y+BUFFER]
    label = tf.cast(label, dtype="float32")
    label = tf.expand_dims(label, axis=-1)
    return label

def extract_subvolume_and_label(location): # Get both data and labels
    subvolume = extract_subvolume(location, volume)
    label = extract_labels(location, labels)
    return subvolume, label

SHUFFLE_BUFFER_SIZE = BATCH_SIZE * 4

final_train_ds = train_locations_ds.map(extract_subvolume_and_label, num_parallel_calls=tf.data.AUTOTUNE)
final_train_ds = final_train_ds.prefetch(tf.data.AUTOTUNE).batch(BATCH_SIZE)

val_locations_stride = BUFFER
val_locations = []
for x in range(val_location[0], val_location[0] + val_zone_size[0], val_locations_stride):
    for y in range(val_location[1], val_location[1] + val_zone_size[1], val_locations_stride):
        val_locations.append((x, y))

val_locations_ds = tf.data.Dataset.from_tensor_slices(val_locations).filter(is_in_mask_train)
val_ds = val_locations_ds.map(extract_subvolume_and_label, num_parallel_calls=tf.data.AUTOTUNE)
val_ds = val_ds.prefetch(tf.data.AUTOTUNE).batch(BATCH_SIZE)


augmenter = keras.Sequential([
    layers.RandomContrast(0.2),
])

def augment_train_data(data, label):
    data = augmenter(data)
    return data, label

augmented_train_ds = final_train_ds.map(augment_train_data, num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE)

def conv_block(hp, input_tensor, num_filters):
    hp_dor = hp.Float('droprate', min_value=0,max_value=.4,step=0.05)
    hp_init = hp.Choice('kern_init', ['glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform'])

    x = tf.keras.layers.Conv2D(num_filters, (3, 3), activation='relu', padding='same', kernel_initializer=hp_init)(input_tensor)
    x = layers.BatchNormalization()(x)
    x = tf.keras.layers.Conv2D(num_filters, (3, 3), activation='relu', padding='same', kernel_initializer=hp_init)(x)
    x = layers.BatchNormalization()(x)

    x = keras.layers.Dropout(hp_dor)(x)

    in_prime = layers.Conv2D(num_filters, (1,1), padding='same')(input_tensor)
    x = layers.add([x,in_prime])

    return x

def plane_conv_block(input_tensor, num_filters,drop_r=0.0,ini="he_normal"):
    x = tf.keras.layers.Conv2D(num_filters, (3, 3), activation='relu', padding='same', kernel_initializer=ini)(input_tensor)
    x = layers.BatchNormalization()(x)
    x = tf.keras.layers.Conv2D(num_filters, (3, 3), activation='relu', padding='same', kernel_initializer=ini)(x)
    x = layers.BatchNormalization()(x)

    x = keras.layers.Dropout(drop_r)(x)

    in_prime = layers.Conv2D(num_filters, (1,1), padding='same')(input_tensor)
    x = layers.add([x,in_prime])

    return x

filters = [256, 128, 64]

class LogCoshDiceLoss(tf.keras.losses.Loss):
    def __init__(self, epsilon=1e-6):
        super(LogCoshDiceLoss, self).__init__()
        self.epsilon = epsilon

    def call(self, y_true, y_pred):
        numerator = 2.0 * tf.reduce_sum(y_true * y_pred, axis=-1)
        denominator = tf.reduce_sum(y_true + y_pred, axis=-1)
        
        dice_score = (numerator + self.epsilon) / (denominator + self.epsilon)
        x = 1 - dice_score
        return tf.math.log((tf.math.exp(x) + tf.math.exp(-x)) / 2.0)

class CombinationLoss(tf.keras.losses.Loss):
    def __init__(self, alpha=0.5, beta=None, balance=0.5, epsilon=1e-6):
        super(CombinationLoss, self).__init__()
        self.alpha = alpha
        if beta is None:
            self.beta = 1.0 - alpha
        else:
            self.beta = beta
        self.balance = balance
        self.epsilon = epsilon

    def get_config(self):
         conf = super().get_config()
         conf.update({"alpha": self.alpha, "beta": self.beta, "epsilon": self.epsilon, "balance": self.balance})
         return conf

    def from_config(self,config=None):
        if config is None:
            return TverskyLoss()
        a = config["alpha"]
        b = config["beta"]
        e = config["epsilon"]
        bal = config["balance"]
        l_i = CombinationLoss(a, b, bal, e)
        return l_i
    
    def call(self, y_true, y_pred):
        #LogCosh
        numerator = 2.0 * tf.reduce_sum(y_true * y_pred, axis=-1)
        denominator = tf.reduce_sum(y_true + y_pred, axis=-1)
        
        dice_score = (numerator + self.epsilon) / (denominator + self.epsilon)
        x = 1 - dice_score
        logcosh_fin = tf.math.log((tf.math.exp(x) + tf.math.exp(-x)) / 2.0)

        #Tversky
        y_true_pos = tf.reshape(y_true, [-1])
        y_pred_pos = tf.reshape(y_pred, [-1])
        true_pos = tf.reduce_sum(y_true_pos * y_pred_pos)
        false_neg = tf.reduce_sum(y_true_pos * (1-y_pred_pos))
        false_pos = tf.reduce_sum((1-y_true_pos)*y_pred_pos)
        tver_fin = 1 - (true_pos + self.epsilon)/(true_pos + self.alpha*false_neg + self.beta*false_pos + self.epsilon) 
        return ((self.balance*logcosh_fin) + ((1-self.balance)*tver_fin)) / 2.0

class TverskyLoss(tf.keras.losses.Loss):
    def __init__(self, alpha=0.5, beta=None, epsilon=1e-6):
        super(TverskyLoss, self).__init__()
        self.alpha = alpha
        if beta is None:
            self.beta = 1 - self.alpha
        else:
            self.beta = beta
        self.epsilon = epsilon

    def call(self, y_true, y_pred):
        y_true_pos = tf.reshape(y_true, [-1])
        y_pred_pos = tf.reshape(y_pred, [-1])
        true_pos = tf.reduce_sum(y_true_pos * y_pred_pos)
        false_neg = tf.reduce_sum(y_true_pos * (1-y_pred_pos))
        false_pos = tf.reduce_sum((1-y_true_pos)*y_pred_pos)
        return 1 - (true_pos + self.epsilon)/(true_pos + self.alpha*false_neg + self.beta*false_pos + self.epsilon)
    def get_config(self):
         conf = super().get_config()
         conf.update({"alpha": self.alpha, "beta": self.beta, "epsilon": self.epsilon})
         return conf
    def from_config(self,config=None):
        if config is None:
            return TverskyLoss()
        a = config["alpha"]
        b = config["beta"]
        e = config["epsilon"]
        l_i = TverskyLoss(a, b, e)
        return l_i

class LossWrapper:
    def __init__(self, name, lossfn, **lossparams):
        self.name = name
        self.loss = lossfn(**lossparams)

def model_builder(hp):
    input_shape = (BUFFER*2, BUFFER*2, Z_DIM) # The 3d volume and the number of color channels(1)
    inputs = layers.Input(input_shape)

    p = inputs 
    skip_connections = []

    # Downsampling
    for f in filters:
        c = conv_block(hp, p, f)
        p = layers.MaxPooling2D(2, strides=(2,2), padding="same")(c)
        skip_connections.append(c)

    # Bottleneck
    bn = conv_block(hp, p, filters[-1])

    skip_connections = list(reversed(skip_connections))

    # Upsampling and establishing the skip connections
    for i, f in enumerate(reversed(filters)):
        bn = keras.layers.UpSampling2D()(bn)
        if i < len(skip_connections):
            bn = layers.concatenate([bn, skip_connections[i]]) # backward residual connection
        bn = conv_block(hp, bn,f)

    # Output layer
    outputs = keras.layers.Conv2D(1, (1, 1), padding='same', activation='sigmoid')(bn)
    model = tf.keras.models.Model(inputs=inputs, outputs=outputs)
    # hp_applybalan = hp.Boolean('appbalan')
    hp_lr = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4, 1e-5])
    hp_weightdecay = hp.Choice('weightdecay', values=[1e-2,1e-3, 1e-4,1e-5])
    lossfns = {
                "TverskyLoss": LossWrapper("TverskyLoss", TverskyLoss, alpha=hp.Float('alpha', min_value=0,max_value=1,step=0.1)),
                "LogCoshDiceLoss": LossWrapper("LogCoshDice", LogCoshDiceLoss),
                "CombinationLoss": LossWrapper("CombinationLoss", CombinationLoss, alpha=hp.Float('alpha', min_value=0,max_value=1,step=0.1), balance=hp.Float('balance', min_value=0,max_value=1,step=0.1)),
                "BinaryCrossEntropyLoss": LossWrapper("BinaryCrossEntropy", keras.losses.BinaryCrossentropy),
                "BinaryFocalCrossEntropyLoss": LossWrapper("BinaryFocalCrossEntropy", keras.losses.BinaryFocalCrossentropy,apply_class_balancing=hp.Boolean('appbalan'),
                                                                                                                           alpha=hp.Float('alpha', min_value=0,max_value=1,step=0.1), 
                                                                                                                           gamma=hp.Float('gamma', min_value=1.0, max_value=4.0, step=1.0))
            }
    hp_loss = hp.Choice('lossfn', values=["TverskyLoss", "LogCoshDiceLoss", "CombinationLoss", "BinaryCrossEntropyLoss", "BinaryFocalCrossEntropyLoss"])
    model.compile(loss=lossfns[hp_loss].loss,
                  optimizer=keras.optimizers.Nadam(learning_rate=hp_lr, weight_decay=hp_weightdecay),
                  metrics=['accuracy', keras.metrics.BinaryIoU(target_class_ids=[0,1], name="biou")])
    return model

def plane_model(input_shape, drop_r, alpha, wd):
    inputs = layers.Input(input_shape)

    p = inputs 
    skip_connections = []

    # Downsampling
    for f in filters:
        c = plane_conv_block(p, f,drop_r)
        p = layers.MaxPooling2D(2, strides=(2,2), padding="same")(c)
        skip_connections.append(c)

    # Bottleneck
    bn = plane_conv_block(p, filters[-1])

    skip_connections = list(reversed(skip_connections))

    # Upsampling and establishing the skip connections
    for i, f in enumerate(reversed(filters)):
        bn = keras.layers.Conv2DTranspose(f, kernel_size=(2,2), strides=2, padding="same")(bn)
        if i < len(skip_connections):
            bn = layers.concatenate([bn, skip_connections[i]]) # backward residual connection
        bn = plane_conv_block(bn, f)

    # Output layer
    outputs = keras.layers.Conv2D(1, (1, 1), padding='same', activation='sigmoid')(bn)
    model = tf.keras.models.Model(inputs=inputs, outputs=outputs)
    model.compile(loss=keras.losses.BinaryCrossentropy(),
                  optimizer=keras.optimizers.Nadam(learning_rate=0.001, weight_decay=wd),
                  metrics=['accuracy', keras.metrics.BinaryIoU(target_class_ids=[0,1], name="biou")])
    return model

if TUNE:
    tuner = tk.BayesianOptimization(model_builder,
                     max_trials=40,
                     objective= ["val_accuracy",tk.Objective(name="val_biou", direction="min")],
                     directory='new_dir',
                     project_name='ink_detect',
                     overwrite=True)
    acc_stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5)
    loss_stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)
    tuner.search(augmented_train_ds, steps_per_epoch=300, epochs=20, callbacks=[acc_stop_early, loss_stop_early], validation_data=val_ds)
    best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]
    model = tuner.hypermodel.build(best_hps)
    model.fit(augmented_train_ds, epochs=30, validation_data=val_ds,shuffle=True,steps_per_epoch=500,callbacks=[acc_stop_early, loss_stop_early])
    model.save(MODEL_FILE)
elif not LOAD_MODEL:
    stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)
    input_shape = (BUFFER*2, BUFFER*2, Z_DIM) # The 3d volume and the number of color channels(1)
    model = plane_model(input_shape, 0.3, 0.4, 0.01)
    model.summary()
    model.fit(augmented_train_ds, epochs=30, validation_data=val_ds,shuffle=True,steps_per_epoch=500,callbacks=[stop_early])
    model.save(MODEL_FILE)
else:
    model = keras.models.load_model(MODEL_FILE,custom_objects={"TverskyLoss": TverskyLoss})
    stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)
    history = model.fit(augmented_train_ds, epochs=30, validation_data=val_ds,shuffle=True,steps_per_epoch=500,callbacks=[stop_early])
    model.summary()

# A sanity check
def extract_subv_l_and_loc(location):
    inout = extract_subvolume_and_label(location)
    loc = location
    return inout, loc

test_stride = BUFFER
test_locations = []
for x in range(val_location[0] - BUFFER*6, val_location[0] + val_zone_size[0] + BUFFER*6, val_locations_stride):
    for y in range(val_location[1], val_location[1] + val_zone_size[1], val_locations_stride):
        test_locations.append((x, y))

test_locations_ds = tf.data.Dataset.from_tensor_slices(test_locations).filter(is_in_mask_train)
test_ds = test_locations_ds.map(extract_subv_l_and_loc, num_parallel_calls=tf.data.AUTOTUNE)
test_ds = test_ds.prefetch(tf.data.AUTOTUNE).batch(1)

fig, (ax1,ax2) = plt.subplots(1,2)
img=ax1.imshow(labels)
xmax,ymax=labels.shape
ax2.imshow(labels)
for io, pos in test_ds.as_numpy_iterator(): # calculate predictions and overlay
    v, l = io
    x, y = pos[0]
    pred = model(v)
    extent=(y,y+(2*BUFFER),x+(2*BUFFER),x)
    ax1.imshow(pred[0],extent=extent)
ax1.set(xlim=(0,ymax), ylim=(xmax,0))
if not RAP_TEST:
    plt.show()
else:
    plt.savefig(f"results_{DROPOUT_R}_{KERNINIT}_{USERESIDUAL}_{ALPHA}_{GAMMA}_{WD}.png")

#Cleanup
del volume
del mask
del labels
del final_train_ds
del val_ds
del test_ds

# Manually trigger garbage collection
keras.backend.clear_session()
import gc
gc.collect()
